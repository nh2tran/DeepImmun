{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     34,
     59,
     63
    ]
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score\n",
    "import pickle\n",
    "import zipfile\n",
    "import io\n",
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tf.__version__ =\", tf.__version__)\n",
    "from tensorflow.keras.layers import Masking, Embedding, Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, TimeDistributed, AveragePooling1D, Activation, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')\n",
    "\n",
    "aa_list = ['_PAD',\n",
    "           'A',\n",
    "           'R',\n",
    "           'N',\n",
    "           'D',\n",
    "           'C',\n",
    "           'E',\n",
    "           'Q',\n",
    "           'G',\n",
    "           'H',\n",
    "           'I',\n",
    "           'L',\n",
    "           'K',\n",
    "           'M',\n",
    "           'F',\n",
    "           'P',\n",
    "           'S',\n",
    "           'T',\n",
    "           'W',\n",
    "           'Y',\n",
    "           'V',\n",
    "          ]\n",
    "vocab_size = len(aa_list)\n",
    "aa2index = {}\n",
    "index2aa = {}\n",
    "for index, aa in enumerate(aa_list):\n",
    "    aa2index[aa] = index\n",
    "    index2aa[index] = aa\n",
    "\n",
    "IEDB_response_code = {'Positive': 1,\n",
    "                      'Positive-High': 1,\n",
    "                      'Positive-Intermediate': 1,\n",
    "                      'Positive-Low': 1,\n",
    "                      'Negative': 0,\n",
    "                     }\n",
    "MAX_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] define T cell tables, running mode, patient, hla_alleles\n",
    "# comment or uncomment the lines below to select the dataset of interest\n",
    "# the default dataset is mel15\n",
    "\n",
    "# use this csv file for human data\n",
    "# tcell_table_file = \"data.training/tcell/iedb.assay_tcell.hla_1.host_human/tcell_table_export_1578821658.csv\"\n",
    "# use this csv file for mouse data\n",
    "tcell_table_file = \"data.training/tcell/iedb.assay_tcell.hla_1.host_mouse/tcell_table_export_1640227737.csv\"\n",
    "\n",
    "# mode = 'real application' # in this mode, there is no data for evaluation\n",
    "# patient = \"melS2\"\n",
    "# hla_alleles = [\"HLA-A*23:01\", \"HLA-A*24:02\", \"HLA-B*81:01\", \"HLA-B*40:01\", \"HLA-C*03:04\", \"HLA-C*07:02\"]\n",
    "\n",
    "mode = 'evaluation' # this mode is for the datasets in the DeepImmun manuscript\n",
    "patient = \"mel15\"\n",
    "hla_alleles = [\"HLA-A*03:01\", \"HLA-A*68:01\", \"HLA-B*27:05\", \"HLA-B*35:03\", \"HLA-C*02:02\", \"HLA-C*04:01\"]\n",
    "# patient = \"mel0D5P\"\n",
    "# hla_alleles = [\"HLA-A*01:01\", \"HLA-A*23:01\", \"HLA-B*07:02\", \"HLA-B*15:01\", \"HLA-C*12:03\", \"HLA-C*14:02\"]\n",
    "# patient = \"mel51\"\n",
    "# hla_alleles = [\"HLA-A*01:01\", \"HLA-A*02:01\", \"HLA-B*14:02\", \"HLA-B*15:01\", \"HLA-C*03:04\", \"HLA-C*08:02\"]\n",
    "# patient = \"mouseEL4\"\n",
    "# hla_alleles = [\"H2-Db\", \"H2-Kb\"]\n",
    "\n",
    "print(\"patient =\", patient)\n",
    "print(\"hla_alleles =\", hla_alleles)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# The code below is organized in this order:\n",
    "#   TRAINING, PREDICTION, EVALUATION\n",
    "# If you only want to do prediction using pretrained models,\n",
    "# you can skip the TRAINING and jump to the PREDICTION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# TRAINING\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     7,
     26,
     39,
     40
    ]
   },
   "outputs": [],
   "source": [
    "# read IEDB tables; select HLA alleles, linear peptides; and prepare training data\n",
    "output_file = \"training_data_copy.csv\"\n",
    "\n",
    "def prepare_training_data(patient, hla_alleles):\n",
    "\n",
    "  # read tcell assays table\n",
    "  assay_dict = {}\n",
    "  with open(tcell_table_file, 'r') as input_handle:\n",
    "    csv_reader = csv.reader(input_handle, delimiter=',')\n",
    "    header_1 = next(csv_reader)\n",
    "    header_2 = next(csv_reader)\n",
    "    header_list = []\n",
    "    for x, y in zip(header_1, header_2):\n",
    "      header_list.append(':'.join([x, y]))\n",
    "    for row in csv_reader:\n",
    "      assert len(row) == len(header_list)\n",
    "      assay = {}\n",
    "      for x, y in zip (header_list, row):\n",
    "        assay[x] = y\n",
    "      assay_id = assay['Reference:T Cell ID']\n",
    "      assay_dict[assay_id] = assay\n",
    "  print(\"len(assay_dict) =\", len(assay_dict))\n",
    "  \n",
    "  print(\"patient =\", patient)\n",
    "  print(\"hla_alleles =\", hla_alleles)\n",
    "  assay_filtered = []\n",
    "  for assay in assay_dict.values():\n",
    "    allele = assay['MHC:Allele Name']\n",
    "    epitope_type = assay['Epitope:Object Type']\n",
    "    if (allele in hla_alleles and epitope_type == \"Linear peptide\"):\n",
    "        assay_filtered.append(assay)\n",
    "\n",
    "  print(\"len(assay_filtered) =\", len(assay_filtered))\n",
    "  peptide_set = set([x['Epitope:Description'] for x in assay_filtered])\n",
    "  print(\"len(peptide_set) =\", len(peptide_set))\n",
    "  print()\n",
    "  \n",
    "  \n",
    "  # output temporary csv\n",
    "  with open(output_file, 'w') as output_handle:\n",
    "    fieldnames = ['Reference:T Cell ID',\n",
    "                  'MHC:Allele Name',\n",
    "                  'Epitope:Epitope ID',\n",
    "                  'Epitope:Object Type',\n",
    "                  'Epitope:Description',\n",
    "                  'Assay:Qualitative Measure',\n",
    "                 ]\n",
    "    csv_writer = csv.DictWriter(output_handle, fieldnames, delimiter=',')\n",
    "    csv_writer.writeheader()\n",
    "    for assay in assay_filtered:\n",
    "      assay_subset = {k:v for k, v in assay.items() if k in fieldnames}\n",
    "      csv_writer.writerow(assay_subset)\n",
    "\n",
    "prepare_training_data(patient, hla_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# read training data\n",
    "training_data_file = \"training_data_copy.csv\"\n",
    "training_pair_list = []\n",
    "peptides_with_unknown_aa = 0\n",
    "allele_freq_dict = {}\n",
    "with open(training_data_file, 'r') as input_handle:\n",
    "    csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        peptide = row['Epitope:Description']\n",
    "        peptide = list(peptide)\n",
    "        peptide_assertion = True\n",
    "        for aa in peptide:\n",
    "            if aa not in aa_list:\n",
    "                peptide_assertion = False\n",
    "                break\n",
    "        if not peptide_assertion:\n",
    "            peptides_with_unknown_aa += 1\n",
    "            continue\n",
    "        response = IEDB_response_code[row['Assay:Qualitative Measure']]\n",
    "        allele = row['MHC:Allele Name']\n",
    "        if allele in allele_freq_dict:\n",
    "            allele_freq_dict[allele] += 1\n",
    "        else:\n",
    "            allele_freq_dict[allele] = 1\n",
    "        training_pair_list.append([peptide, response])\n",
    "\n",
    "print(\"allele_freq_dict =\", allele_freq_dict)\n",
    "print(\"peptides_with_unknown_aa = \", peptides_with_unknown_aa)\n",
    "print(\"len(training_pair_list) = \", len(training_pair_list))\n",
    "print(\"  positive = \", len([y for x, y in training_pair_list if y == 1]))\n",
    "print(\"  negative = \", len([y for x, y in training_pair_list if y == 0]))\n",
    "print(\"training_pair_list[0] = \", training_pair_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] add self peptides from normal_hla.txt files\n",
    "print(\"len(training_pair_list) \", len(training_pair_list))\n",
    "normal_hla_file = patient + \"_normal_hla.txt\" # \"mel15_normal_hla.txt\"\n",
    "print(\"normal_hla_file =\", normal_hla_file)\n",
    "with open(normal_hla_file, 'r') as input_handle:\n",
    "    normal_hla = input_handle.readlines()\n",
    "    normal_hla = [x.strip() for x in normal_hla]\n",
    "normal_hla_neg = [[list(x), 0] for x in normal_hla]\n",
    "print(\"len(normal_hla_neg) =\", len(normal_hla_neg))\n",
    "print(\"normal_hla_neg[0] =\", normal_hla_neg[0])\n",
    "\n",
    "training_pair_list_pos = [[x, y] for x, y in training_pair_list if y == 1]\n",
    "print(\"len(training_pair_list_pos) \", len(training_pair_list_pos))\n",
    "training_pair_list = training_pair_list_pos + normal_hla_neg\n",
    "print(\"len(training_pair_list) \", len(training_pair_list))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] exclude mutated_test_set under evaluation mode\n",
    "print(\"mode =\", mode)\n",
    "if mode == 'evaluation':\n",
    "    print(\"len(training_pair_list) =\", len(training_pair_list))\n",
    "    mutated_test_file = \"test.\" + patient + \".csv\" # \"test.mel15.csv\"\n",
    "    print(\"mutated_test_file =\", mutated_test_file)\n",
    "    mutated_test_list = set()\n",
    "    if mutated_test_file[-3:] == 'csv':\n",
    "        with open(mutated_test_file, 'r') as csv_handle:\n",
    "            csv_reader = csv.DictReader(csv_handle)\n",
    "            mutated_test_list = [row['peptide'] for row in csv_reader]\n",
    "    elif mutated_test_file[-3:] == 'txt':\n",
    "        with open(mutated_test_file, 'r') as file:\n",
    "            mutated_test_list= [x.strip() for x in file.readlines()]\n",
    "    print(\"len(mutated_test_list) =\", len(mutated_test_list))\n",
    "    training_overlap_mutated_test = [''.join(x[0]) for x in training_pair_list if ''.join(x[0]) in mutated_test_list]\n",
    "    print(\"len(training_overlap_mutated_test) =\", len(training_overlap_mutated_test))\n",
    "    training_overlap_mutated_test = {x:training_overlap_mutated_test.count(x) for x in set(training_overlap_mutated_test)}\n",
    "    print(\"training_overlap_mutated_test =\", training_overlap_mutated_test)\n",
    "    print(\"Exclude training_overlap_mutated_test\")\n",
    "    training_pair_list = [x for x in training_pair_list if ''.join(x[0]) not in mutated_test_list]\n",
    "    print(\"len(training_pair_list) =\", len(training_pair_list))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# reduce training data to peptides rather than assays, filter out overlapping pos/neg peptides, filter length_8_14\n",
    "print(\"len(training_pair_list) = \", len(training_pair_list))\n",
    "peptide_set = set([''.join(x) for x, y in training_pair_list])\n",
    "peptide_set_pos = set([''.join(x) for x, y in training_pair_list if y == 1])\n",
    "peptide_set_neg = set([''.join(x) for x, y in training_pair_list if y == 0])\n",
    "peptide_overlap = peptide_set_pos.intersection(peptide_set_neg)\n",
    "print(\"len(peptide_set) = \", len(peptide_set))\n",
    "print(\"  len(peptide_set_pos) = \", len(peptide_set_pos))\n",
    "print(\"  len(peptide_set_neg) = \", len(peptide_set_neg))\n",
    "print(\"  len(peptide_overlap) = \", len(peptide_overlap))\n",
    "print(\"peptide_overlap =\", peptide_overlap)\n",
    "# convert set to sorted list to maintain the abc order\n",
    "peptide_set_pos = sorted(list(peptide_set_pos))\n",
    "peptide_set_neg = sorted(list(peptide_set_neg))\n",
    "training_pair_list = [[list(x), 1] for x in peptide_set_pos] + [[list(x), 0] for x in peptide_set_neg]\n",
    "training_pair_list = [[x, y] for x, y in training_pair_list if ''.join(x) not in peptide_overlap or y == 1]\n",
    "print(\"len(training_pair_list) = \", len(training_pair_list))\n",
    "print(\"  positive = \", len([y for x, y in training_pair_list if y == 1]))\n",
    "print(\"  negative = \", len([y for x, y in training_pair_list if y == 0]))\n",
    "print(\"training_pair_list[0] = \", training_pair_list[0])\n",
    "print()\n",
    "\n",
    "print(\"Filter length_8_14\")\n",
    "training_pair_list = [[x, y] for x, y in training_pair_list if len(x) >= 8 and len(x) <= 14]\n",
    "print(\"len(training_pair_list) = \", len(training_pair_list))\n",
    "print(\"training_pair_list[0] = \", training_pair_list[0])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     11,
     27
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] split train/valid/test and upsampling/downsampling\n",
    "print(\"len(training_pair_list) = \", len(training_pair_list))\n",
    "train_valid_set, test_set = train_test_split(training_pair_list, test_size=0.1, random_state=99)\n",
    "train_set, valid_set = train_test_split(train_valid_set, test_size=0.1, random_state=99)\n",
    "print(\"len(train_set) = \", len(train_set))\n",
    "print(\"len(valid_set) = \", len(valid_set))\n",
    "print(\"len(test_set) = \", len(test_set))\n",
    "print()\n",
    "\n",
    "# save the test_set for future evaluation\n",
    "# test_set_file = \"test_set.\" + patient + \".csv\" # \"test_set.mel15.csv\"\n",
    "# with open(test_set_file, 'w') as file:\n",
    "#     csv_writer = csv.DictWriter(file, fieldnames=['peptide', 'response'])\n",
    "#     csv_writer.writeheader()\n",
    "#     for peptide, response in test_set:\n",
    "#         peptide = ''.join(peptide)\n",
    "#         response = 'positive' if response else 'negative'\n",
    "#         csv_writer.writerow({'peptide': peptide, 'response': response})\n",
    "# print(\"test_set_file =\", test_set_file)\n",
    "# print()\n",
    "\n",
    "train_set_neg = [x for x in train_set if x[1] == 0]\n",
    "train_set_pos = [x for x in train_set if x[1] == 1]\n",
    "print(\"len(train_set_neg) =\", len(train_set_neg))\n",
    "print(\"len(train_set_pos) =\", len(train_set_pos))\n",
    "print()\n",
    "\n",
    "def prepare_tensor(training_set):\n",
    "    x_peptide = [x for x, y in training_set]\n",
    "    y_tensor = np.array([y for x, y in training_set])\n",
    "    x_tensor = [[aa2index[aa] for aa in peptide] for peptide in x_peptide]\n",
    "    x_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      x_tensor, \n",
    "      maxlen=MAX_LEN,\n",
    "      dtype='int32',\n",
    "      padding='post',\n",
    "      value=0)\n",
    "    return x_tensor, y_tensor\n",
    "\n",
    "# x_train, y_train = prepare_tensor(train_set)\n",
    "x_valid, y_valid = prepare_tensor(valid_set)\n",
    "x_test, y_test = prepare_tensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] model training\n",
    "def train_model(x_train, y_train, x_valid, y_valid, model_path, num_epochs):\n",
    "#     print(\"\".join([\"=\"] * 80)) # section-separating line\n",
    "#     print(\"train_model()\")\n",
    "\n",
    "    # Model Training\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=8, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(8, recurrent_initializer='glorot_uniform')))\n",
    "    model.add(Dense(1, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    # dropout causes fluctuations ??\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    #print(model.summary())\n",
    "    #model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "    model_checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        verbose=0,\n",
    "                        callbacks=[model_checkpoint])\n",
    "    \n",
    "#     fig, ax = pyplot.subplots(1, 2)\n",
    "#     ax[0].plot(history.history['loss'])\n",
    "#     ax[0].plot(history.history['val_loss'])\n",
    "#     ax[0].set_ylabel('loss')\n",
    "#     ax[0].set_xlabel('epoch')\n",
    "#     ax[0].legend(['loss', 'val_loss'], loc='upper left')\n",
    "#     ax[1].plot(history.history['auc'])\n",
    "#     ax[1].plot(history.history['val_auc'])\n",
    "#     ax[1].set_ylabel('auc')\n",
    "#     ax[1].set_xlabel('epoch')\n",
    "#     ax[1].legend(['auc', 'val_auc'], loc='upper left')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model training\n",
    "print(\"model training\")\n",
    "model_name = patient + \"_copy\"\n",
    "model_number = 100\n",
    "model_paths = [model_name + \"/\" + \"model\" + \"_\" + model_name + \"_\" + str(m) + \".h5\" for m in range(model_number)]\n",
    "model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "print(\"len(model_paths) =\", len(model_paths))\n",
    "print(\"model_paths[0] =\", model_paths[0])\n",
    "print(\"model_score_path =\", model_score_path)\n",
    "print()\n",
    "num_epochs = 100\n",
    "for i, path in enumerate(model_paths):\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        continue\n",
    "    \n",
    "    print(\"path =\", path)\n",
    "    \n",
    "    random.seed(99 + i)\n",
    "    \n",
    "#     # no sampling\n",
    "#     train_set = train_set_neg + train_set_pos\n",
    "\n",
    "    # downsampling negative samples\n",
    "    train_set_neg_down = random.sample(train_set_neg, k=len(train_set_pos))\n",
    "    train_set = train_set_neg_down + train_set_pos\n",
    "\n",
    "#     # downsampling positive samples\n",
    "#     train_set_pos_down = random.sample(train_set_pos, k=len(train_set_neg))\n",
    "#     train_set = train_set_pos_down + train_set_neg\n",
    "    \n",
    "    random.shuffle(train_set)\n",
    "    x_train, y_train = prepare_tensor(train_set)\n",
    "    \n",
    "    # model training\n",
    "    model = train_model(x_train, y_train, x_valid, y_valid, path, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# make predictions on valid set and save the results for model selection\n",
    "if not os.path.isfile(model_score_path):\n",
    "    print(\"make predictions on valid set and save the results for model selection\")\n",
    "    x_testing, y_testing = prepare_tensor(valid_set)\n",
    "#     print(\"combine valid + test for more accurate model selection\")\n",
    "#     x_testing, y_testing = prepare_tensor(valid_set + test_set)\n",
    "    print(\"len(y_testing) =\", len(y_testing))\n",
    "    print()\n",
    "    y_pred_list = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "        model = load_model(path)\n",
    "        y_pred = model.predict(x_testing).flatten()\n",
    "        y_pred_list.append(y_pred)\n",
    "    model_score = [y_testing, y_pred_list]\n",
    "    with open(model_score_path, 'wb') as file:\n",
    "        pickle.dump(model_score, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# PREDICTION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] model selection\n",
    "# before running this code, please add \"_copy\" to the model folder name, e.g. \"mel15_copy\"\n",
    "\n",
    "print(\"model selection\")\n",
    "model_name = patient + \"_copy\"\n",
    "model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "print(\"model_score_path =\", model_score_path)\n",
    "with open(model_score_path, 'rb') as file:\n",
    "    model_score = pickle.load(file) # y_testing, y_pred_list\n",
    "y_testing, y_pred_list = model_score\n",
    "print(\"len(y_pred_list) =\", len(y_pred_list))\n",
    "print()\n",
    "\n",
    "print(\"AUC of the average of the best models\")\n",
    "testing_auc_list = [roc_auc_score(y_testing, y_pred) for y_pred in y_pred_list]\n",
    "pyplot.boxplot(testing_auc_list)\n",
    "sorted_auc_indices = sorted(range(len(testing_auc_list)), key=lambda k: -testing_auc_list[k])\n",
    "for best in [1, 10, 20, 40, 60, 80, len(testing_auc_list)]:\n",
    "    y_pred_avg = np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "    y_pred_avg_auc = roc_auc_score(y_testing, y_pred_avg)\n",
    "    print(best, \"best models\", y_pred_avg_auc)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot the score distribution of the average of the best models\n",
    "print(\"plot the score distribution of the average of the best models\")\n",
    "best = 10\n",
    "print(best, \"best models\")\n",
    "y_score =  np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "fig, ax = pyplot.subplots(1, 2)\n",
    "fpr, tpr, _ = roc_curve(y_testing, y_score)\n",
    "auc = roc_auc_score(y_testing, y_score)\n",
    "ax[0].plot(fpr,tpr,label=\"data 1, auc={:.2f}\".format(auc))\n",
    "ax[0].set_ylabel('True Positive Rate')\n",
    "ax[0].set_xlabel('False Positive Rate')\n",
    "ax[0].legend(loc=4)\n",
    "\n",
    "y_score_0 = [b for a, b in zip(y_testing, y_score) if a == 0]\n",
    "y_score_1 = [b for a, b in zip(y_testing, y_score) if a == 1]\n",
    "my_dict = {'neg': y_score_0, 'pos': y_score_1}\n",
    "ax[1].boxplot(my_dict.values())\n",
    "ax[1].set_xticklabels(my_dict.keys())\n",
    "pd_0 = pd.DataFrame({'neg': y_score_0})\n",
    "pd_1 = pd.DataFrame({'pos': y_score_1})\n",
    "pd.concat([pd_0, pd_1], ignore_index=True, axis=1).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     14,
     31,
     42,
     89
    ]
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "# function to draw random peptides of length 8-14 aa from swissprot.human.2020_06_15.fasta\n",
    "fasta_path = \"data.fasta/swissprot.human.2020_06_15.fasta\"\n",
    "print(\"fasta_path =\", fasta_path)\n",
    "num_proteins = 0\n",
    "super_protein = ''\n",
    "for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "    super_protein += str(record.seq)\n",
    "    num_proteins += 1\n",
    "print(\"num_proteins = \", num_proteins)\n",
    "print(\"len(super_protein) = \", len(super_protein))\n",
    "print()\n",
    "\n",
    "def draw_random_peptides(num_peptides, super_protein):\n",
    "    print(\"draw_random_peptides()\")\n",
    "    print(\"num_peptides =\", num_peptides)\n",
    "    super_protein_len = len(super_protein)\n",
    "    random.seed(99)\n",
    "    start_positions = random.choices(range(super_protein_len), k=num_peptides)\n",
    "    lengths = random.choices(range(8, 14), k=num_peptides)\n",
    "    random_peptide_list = [super_protein[s:s+l] for s,l in zip(start_positions, lengths)]\n",
    "    random_peptide_list = sorted(set(random_peptide_list))\n",
    "    random_peptide_list = [x for x in random_peptide_list if all([aa in aa_list for aa in x])]\n",
    "    print(\"len(random_peptide_list) =\", len(random_peptide_list))\n",
    "    print()\n",
    "    return random_peptide_list\n",
    "# random_peptide_list = draw_random_peptides(10, super_protein)\n",
    "# print(random_peptide_list)\n",
    "# print()\n",
    "\n",
    "def predict_sub(model, peptide_list):\n",
    "    x_tensor = [[aa2index[aa] for aa in peptide] for peptide in peptide_list]\n",
    "    x_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      x_tensor, \n",
    "      maxlen=MAX_LEN,\n",
    "      dtype='int32',\n",
    "      padding='post',\n",
    "      value=0)\n",
    "    y_pred = model.predict(x_tensor).flatten()\n",
    "    return y_pred\n",
    "\n",
    "def predict(model_list, model_score, input_file, output_file):\n",
    "#     print(\"predict()\")\n",
    "#     print(\"input_file = \", input_file)\n",
    "#     print(\"output_file = \", output_file)\n",
    "\n",
    "    if input_file[-3:] == 'csv':\n",
    "        with open(input_file, 'r') as input_handle:\n",
    "            csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "            csv_fieldnames = csv_reader.fieldnames\n",
    "            csv_records = list(csv_reader)\n",
    "    elif input_file[-3:] == 'txt':\n",
    "        with open(input_file, 'r') as file:\n",
    "            csv_fieldnames = ['peptide']\n",
    "            csv_records = [{'peptide':x.strip()} for x in file.readlines()]\n",
    "    print(\"number of input peptides =\", len(csv_records))\n",
    "    print()\n",
    "\n",
    "    y_pred_list = []\n",
    "    for model in model_list:\n",
    "        y_pred = predict_sub(model, [record['peptide'] for record in csv_records])\n",
    "        y_pred_list.append(y_pred)\n",
    "    y_pred = np.mean(y_pred_list, axis=0)\n",
    "    y_pred_std = np.std(y_pred_list, axis=0)\n",
    "\n",
    "    random_peptide_list = draw_random_peptides(10000, super_protein)\n",
    "    y_random_list = []\n",
    "    for model in model_list:\n",
    "        y_random = predict_sub(model, random_peptide_list)\n",
    "        y_random_list.append(y_random)\n",
    "    y_random = np.mean(y_random_list, axis=0)\n",
    "\n",
    "    model_y_test, model_y_pred = model_score\n",
    "    model_y_pred_0 = [b for (a, b) in zip(model_y_test, model_y_pred) if a == 0]\n",
    "    model_y_pred_1 = [b for (a, b) in zip(model_y_test, model_y_pred) if a == 1]\n",
    "    with open(output_file, 'w') as output_handle:\n",
    "        csv_fieldnames += ['dpImmun', 'dpImmun_std', 'dpImmun_neg_pct', 'dpImmun_pos_pct', 'dpImmun_10k_pct']\n",
    "        csv_writer = csv.DictWriter(output_handle, csv_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for record, pred, pred_std in zip(csv_records, list(y_pred), list(y_pred_std)):\n",
    "            record.update({'dpImmun': pred,\n",
    "                           'dpImmun_std': pred_std,\n",
    "                           'dpImmun_neg_pct': np.sum(pred >= model_y_pred_0) / len(model_y_pred_0),\n",
    "                           'dpImmun_pos_pct': np.sum(pred >= model_y_pred_1) / len(model_y_pred_1),\n",
    "                           'dpImmun_10k_pct': np.sum(pred >= y_random) / len(y_random),\n",
    "                          })\n",
    "            csv_writer.writerow(record)\n",
    "\n",
    "def predict_rescore(model, input_file, output_file):\n",
    "    print(\"predict()\")\n",
    "    print(\"input_file = \", input_file)\n",
    "    print(\"output_file = \", output_file)\n",
    "    peptide_list = []\n",
    "    response_list = []\n",
    "    score_list = []\n",
    "    rank_list = []\n",
    "    with open(input_file, 'r') as input_handle:\n",
    "        csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            peptide = row['peptide']\n",
    "            response = row['response']\n",
    "            score = float(row['Ave'])\n",
    "            rank = float(row['Rank'])\n",
    "            peptide_list.append(peptide)\n",
    "            response_list.append(response)\n",
    "            score_list.append(score)\n",
    "            rank_list.append(rank)\n",
    "    y_pred = predict_sub(model, peptide_list)\n",
    "    y_rescore = np.sqrt(y_pred * np.array(score_list))\n",
    "    with open(output_file, 'w') as output_handle:\n",
    "        headers = ['peptide','response', 'Ave', 'Rank', 'dpImmun', 'dpImmun_rescore']\n",
    "        csv_writer = csv.DictWriter(output_handle, fieldnames=headers)\n",
    "        csv_writer.writeheader()\n",
    "        for peptide, response, score, rank, pred, rescore in zip(\n",
    "            peptide_list, response_list, score_list, rank_list, list(y_pred), list(y_rescore)):\n",
    "            csv_writer.writerow({'peptide': peptide,\n",
    "                                 'response': response,\n",
    "                                 'Ave': score,\n",
    "                                 'Rank': rank,\n",
    "                                 'dpImmun': pred,\n",
    "                                 'dpImmun_rescore': rescore})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] patient prediction\n",
    "print(\"patient prediction\")\n",
    "input_file = \"test.\" + patient + \".csv\" # \"test.mel15.csv\n",
    "output_file = input_file + \".dpimmun.csv\"\n",
    "# input_file = \"deepnovo_peptides.csv.sequence.txt\"\n",
    "# output_file = \"deepnovo_peptides.csv.dpimmun.csv\"\n",
    "print(\"input_file = \", input_file)\n",
    "print(\"output_file = \", output_file)\n",
    "\n",
    "model_number = 100\n",
    "model_paths = [model_name + \"/\" + \"model\" + \"_\" + model_name + \"_\" + str(m) + \".h5\" for m in range(model_number)]\n",
    "model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "print(\"len(model_paths) =\", len(model_paths))\n",
    "print(\"model_paths[0] =\", model_paths[0])\n",
    "print(\"model_score_path =\", model_score_path)\n",
    "print()\n",
    "\n",
    "# use average of the best models for predictions\n",
    "best = 10\n",
    "print(best, \"best models\")\n",
    "print()\n",
    "model_list = [load_model(model_paths[i]) for i in sorted_auc_indices[:best]]\n",
    "with open(model_score_path, 'rb') as file:\n",
    "    model_score = pickle.load(file) # y_testing, y_pred_list\n",
    "y_testing, y_pred_list = model_score\n",
    "y_pred_avg = np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "predict(model_list, [y_testing, y_pred_avg], input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# EVALUATION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     41,
     44,
     60,
     62,
     64,
     66,
     68,
     71
    ]
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def evaluate_sub(y_test, y_score, threshold):\n",
    "#     y_pred = (y_score >= threshold).astype(int)\n",
    "#     y_true = (y_pred == y_test).astype(int)\n",
    "#     y_true_pos = y_true * y_test\n",
    "#     y_true_neg = y_true * (1 - y_test)\n",
    "#     pred_sensitivity = np.sum(y_true_pos) / np.sum(y_test)\n",
    "#     pred_specifity = np.sum(y_true_neg) / np.sum(1 - y_test)\n",
    "#     pred_precision = np.sum(y_true_pos) / np.sum(y_pred)\n",
    "#     pred_precision_neg = np.sum(y_true_neg) / np.sum(1 - y_pred)\n",
    "#     pred_accuracy = np.sum(y_true) / len(y_true)\n",
    "#     pred_accuracy_balanced = (pred_sensitivity + pred_specifity) / 2\n",
    "#     pred_auc = roc_auc_score(y_test, y_score)\n",
    "#     pred_f1 = 1 / ((1/pred_sensitivity + 1/pred_precision) / 2)\n",
    "    \n",
    "#     sorted_index = np.argsort(-y_score)\n",
    "#     y_test_sorted = y_test[sorted_index]\n",
    "#     top20 = y_test_sorted[:20]\n",
    "#     top20_pos = np.sum(top20)\n",
    "#     top20_precision = top20_pos / 20\n",
    "#     top20_sensitivity = top20_pos / np.sum(y_test)\n",
    "#     pos_rank = [index+1 for index, val in enumerate(y_test_sorted) if val == 1]\n",
    "#     pos_rank_median = np.median(pos_rank)\n",
    "    \n",
    "#     print(\"pred_sensitivity = \", pred_sensitivity)\n",
    "#     print(\"pred_specifity = \", pred_specifity)\n",
    "#     print(\"pred_precision = \", pred_precision)\n",
    "#     print(\"pred_precision_neg = \", pred_precision_neg)\n",
    "#     print(\"pred_accuracy = \", pred_accuracy)\n",
    "#     print(\"pred_accuracy_balanced = \", pred_accuracy_balanced)\n",
    "#     print(\"pred_auc = \", pred_auc)\n",
    "#     print(\"pred_f1 = \", pred_f1)\n",
    "#     print(\"top20_pos = \", top20_pos)\n",
    "#     print(\"top20_precision = \", top20_precision)\n",
    "#     print(\"top20_sensitivity = \", top20_sensitivity)\n",
    "#     print(\"pos_rank_median = \", pos_rank_median)\n",
    "#     print()\n",
    "    \n",
    "    auc  = roc_auc_score(y_test, y_score)\n",
    "    return auc\n",
    "\n",
    "def evaluate(input_file, tool_name):\n",
    "    y_test = []\n",
    "    y_score = []\n",
    "    with open(input_file, 'r') as input_handle:\n",
    "        csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            peptide = row['peptide']\n",
    "            response = row['response']\n",
    "            assert response == \"positive\" or response == \"negative\"\n",
    "            response = 1 if response == \"positive\" else 0\n",
    "            y_test.append(response)\n",
    "            score = float(row[tool_name])\n",
    "            if \"%rank\" in tool_name:\n",
    "                score = 1 - score\n",
    "            y_score.append(score)\n",
    "    y_test = np.array(y_test)\n",
    "    y_score = np.array(y_score)\n",
    "\n",
    "    threshold =0.0\n",
    "    if tool_name == 'PRIME':\n",
    "        threshold = 0.0\n",
    "    elif tool_name == 'NetMHCpan':\n",
    "        threshold = 0.0\n",
    "    elif tool_name == 'IEDB':\n",
    "        threshold = 0.0\n",
    "    elif tool_name == 'dpImmun':\n",
    "        threshold = 0.5\n",
    "    elif tool_name == 'Rank':\n",
    "        y_score = -y_score # for NetMHCpan rank, lower is better\n",
    "        threshold = -2.0\n",
    "    elif tool_name == 'dpImmun_rescore':\n",
    "        threshold = 0.5\n",
    "    \n",
    "    return y_test, y_score, evaluate_sub(y_test, y_score, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# [need input] patient auc evaluation\n",
    "eval_file = \"test.\" + patient + \".csv.dpimmun.csv\"\n",
    "print(\"auc evaluation\")\n",
    "print(\"eval_file =\", eval_file)\n",
    "print()\n",
    "tools = ['dpImmun', 'PRIME %rank', 'NetMHCpan %rank', 'IEDB']\n",
    "tools_auc = [evaluate(eval_file, tool) for tool in tools]\n",
    "names = ['dpImmun', 'PRIME', 'NetMHCpan', 'IEDB']\n",
    "colors = ['red', 'orange', 'green', 'blue']\n",
    "\n",
    "pyplot.title('Receiver Operating Characteristic Curves')\n",
    "for y, n, c in zip(tools_auc, names, colors):\n",
    "#     print(n, y[2], sep='\\t')\n",
    "    fpr, tpr, threshold = roc_curve(y[0], y[1])\n",
    "    pyplot.plot(fpr, tpr, color=c, label=\"{0:s}, AUC={1:0.2f}\".format(n, y[2]))\n",
    "pyplot.legend(loc = 'lower right')\n",
    "pyplot.xlim([0, 1])\n",
    "pyplot.ylim([0, 1.05])\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "#     pyplot.show()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_tf2",
   "language": "python",
   "name": "python3_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
