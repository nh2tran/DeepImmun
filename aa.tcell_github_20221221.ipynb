{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     34,
     59
    ]
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score\n",
    "import pickle\n",
    "import zipfile\n",
    "import io\n",
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tf.__version__ =\", tf.__version__)\n",
    "from tensorflow.keras.layers import Masking, Embedding, Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, TimeDistributed, AveragePooling1D, Activation, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')\n",
    "\n",
    "aa_list = ['_PAD',\n",
    "           'A',\n",
    "           'R',\n",
    "           'N',\n",
    "           'D',\n",
    "           'C',\n",
    "           'E',\n",
    "           'Q',\n",
    "           'G',\n",
    "           'H',\n",
    "           'I',\n",
    "           'L',\n",
    "           'K',\n",
    "           'M',\n",
    "           'F',\n",
    "           'P',\n",
    "           'S',\n",
    "           'T',\n",
    "           'W',\n",
    "           'Y',\n",
    "           'V',\n",
    "          ]\n",
    "vocab_size = len(aa_list)\n",
    "aa2index = {}\n",
    "index2aa = {}\n",
    "for index, aa in enumerate(aa_list):\n",
    "    aa2index[aa] = index\n",
    "    index2aa[index] = aa\n",
    "\n",
    "IEDB_response_code = {'Positive': 1,\n",
    "                      'Positive-High': 1,\n",
    "                      'Positive-Intermediate': 1,\n",
    "                      'Positive-Low': 1,\n",
    "                      'Negative': 0,\n",
    "                     }\n",
    "MAX_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# define patient, hla_alleles, running mode, T cell tables\n",
    "# comment or uncomment the lines below to select the dataset of interest\n",
    "# the default dataset is mel15\n",
    "\n",
    "tcell_table_file = \"tcell_table_export_1665561938.csv\"\n",
    "hla_table_file = \"mhc_ligand_full.csv.hla_1.host_human.csv\"\n",
    "\n",
    "mode = 'evaluation' # this mode is for the datasets in the DeepImmun manuscript\n",
    "patient = \"mel15\"\n",
    "hla_alleles = [\"HLA-A*03:01\", \"HLA-A*68:01\", \"HLA-B*27:05\", \"HLA-B*35:03\", \"HLA-C*02:02\", \"HLA-C*04:01\"]\n",
    "# patient = \"mel0D5P\"\n",
    "# hla_alleles = [\"HLA-A*01:01\", \"HLA-A*23:01\", \"HLA-B*07:02\", \"HLA-B*15:01\", \"HLA-C*12:03\", \"HLA-C*14:02\"]\n",
    "# patient = \"mel51\"\n",
    "# hla_alleles = [\"HLA-A*01:01\", \"HLA-A*02:01\", \"HLA-B*14:02\", \"HLA-B*15:01\", \"HLA-C*03:04\", \"HLA-C*08:02\"]\n",
    "# patient = \"iSPC2_IFN\"\n",
    "# hla_alleles = [\"HLA-A*01:01\", \"HLA-A*02:01\", \"HLA-B*15:03\", \"HLA-B*53:01\", \"HLA-C*02:10\", \"HLA-C*04:01\"]\n",
    "# patient = \"mouseEL4\"\n",
    "# hla_alleles = [\"H2-Db\", \"H2-Kb\"]\n",
    "# patient = \"L011\"\n",
    "# hla_alleles = ['HLA-A*11:01','HLA-A*24:02','HLA-B*35:01','HLA-B*49:01']\n",
    "# patient = \"L012\"\n",
    "# hla_alleles = ['HLA-A*11:01','HLA-A*24:02','HLA-B*07:02']\n",
    "# patient = \"L013\"\n",
    "# hla_alleles = ['HLA-A*02:01','HLA-A*32:01','HLA-B*15:01','HLA-B*44:02']\n",
    "# patient = \"CTE0010\"\n",
    "# hla_alleles = ['HLA-A*02:01','HLA-A*31:01','HLA-B*15:01','HLA-B*35:02','HLA-C*03:03','HLA-C*04:01']\n",
    "# patient = \"CTE0015\"\n",
    "# hla_alleles = ['HLA-A*11:01','HLA-A*02:14','HLA-B*07:02','HLA-B*27:05','HLA-C*02:02','HLA-C*07:02']\n",
    "# patient = \"1024002\"\n",
    "# hla_alleles = ['HLA-A*68:01','HLA-B*40:02','HLA-B*40:27','HLA-C*03:04']\n",
    "# patient = \"CU04\"\n",
    "# hla_alleles = ['HLA-A*24:26','HLA-A*26:01','HLA-B*18:01','HLA-B*38:01','HLA-C*12:03']\n",
    "# patient = \"ott1\"\n",
    "# hla_alleles = ['HLA-A*02:01','HLA-A*24:02','HLA-B*44:02','HLA-B*15:01']\n",
    "# patient = \"ott2\"\n",
    "# hla_alleles = ['HLA-A*01:01','HLA-B*38:01','HLA-B*56:01']\n",
    "# patient = \"ott3\"\n",
    "# hla_alleles = ['HLA-A*02:01','HLA-A*03:01','HLA-B*47:01','HLA-B*27:05']\n",
    "# patient = \"ott4\"\n",
    "# hla_alleles = ['HLA-A*02:01','HLA-A*25:01','HLA-B*18:01','HLA-B*27:02']\n",
    "# patient = \"ott5\"\n",
    "# hla_alleles = ['HLA-A*66:01','HLA-A*23:01','HLA-B*41:02','HLA-B*35:01']\n",
    "# patient = \"ott6\"\n",
    "# hla_alleles = ['HLA-A*66:01','HLA-A*01:03','HLA-B*08:01']\n",
    "# patient = \"rajasagi1\"\n",
    "# hla_alleles = ['HLA-A*33:01','HLA-A*68:12','HLA-B*35:01','HLA-B*14:01']\n",
    "\n",
    "print(\"tcell_table_file =\", tcell_table_file)\n",
    "print(\"hla_table_file =\", hla_table_file)\n",
    "print(\"mode =\", mode)\n",
    "print(\"patient =\", patient)\n",
    "print(\"hla_alleles =\", hla_alleles)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# The code below is organized in this order:\n",
    "#   TRAINING, PREDICTION, EVALUATION\n",
    "# If you only want to do prediction or evaluation,\n",
    "# skip the TRAINING and jump to PREDICTION or EVALUATION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# TRAINING\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# read IEDB tables; select HLA alleles, linear peptides; and prepare training data\n",
    "print(\"Read IEDB T cell assay table\")\n",
    "print(\"tcell_table_file =\", tcell_table_file)\n",
    "\n",
    "def prepare_training_data():\n",
    "\n",
    "    # read tcell assays table\n",
    "    assay_dict = {}\n",
    "    with open(tcell_table_file, 'r') as input_handle:\n",
    "        csv_reader = csv.reader(input_handle, delimiter=',')\n",
    "        header_1 = next(csv_reader)\n",
    "        header_2 = next(csv_reader)\n",
    "        header_list = []\n",
    "        for x, y in zip(header_1, header_2):\n",
    "            header_list.append(':'.join([x, y]))\n",
    "        for row in csv_reader:\n",
    "            assert len(row) == len(header_list)\n",
    "            assay = {}\n",
    "            for x, y in zip (header_list, row):\n",
    "                assay[x] = y\n",
    "            assay_id = assay['Reference:T Cell ID']\n",
    "            assay_dict[assay_id] = assay\n",
    "    print(\"len(assay_dict) =\", len(assay_dict))\n",
    "\n",
    "    print(\"patient =\", patient)\n",
    "    print(\"hla_alleles =\", hla_alleles)\n",
    "    assay_filtered = []\n",
    "    allele_freq_dict = {}\n",
    "    iedb_pair_list = []\n",
    "    for assay in assay_dict.values():\n",
    "        allele = assay['MHC:Allele Name']\n",
    "        epitope_type = assay['Epitope:Object Type']\n",
    "        peptide = assay['Epitope:Description']\n",
    "        response = IEDB_response_code[assay['Assay:Qualitative Measure']]\n",
    "        if not (allele in hla_alleles and epitope_type == \"Linear peptide\" and all([aa in aa_list for aa in peptide])):\n",
    "            continue\n",
    "        assay_filtered.append(assay)\n",
    "        if allele in allele_freq_dict:\n",
    "            allele_freq_dict[allele] += 1\n",
    "        else:\n",
    "            allele_freq_dict[allele] = 1\n",
    "        iedb_pair_list.append([peptide, response])\n",
    "\n",
    "    print(\"len(assay_filtered) =\", len(assay_filtered))\n",
    "    print(\"allele_freq_dict =\", allele_freq_dict)\n",
    "    print(\"len(iedb_pair_list) = \", len(iedb_pair_list))\n",
    "    print(\"  positive = \", len([y for x, y in iedb_pair_list if y == 1]))\n",
    "    print(\"  negative = \", len([y for x, y in iedb_pair_list if y == 0]))\n",
    "    print(\"iedb_pair_list[0] = \", iedb_pair_list[0])\n",
    "    print()\n",
    "    \n",
    "    return iedb_pair_list\n",
    "\n",
    "iedb_pair_list = prepare_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     25
    ]
   },
   "outputs": [],
   "source": [
    "# add self peptides and/or allele peptides; select personalized model; prepare training_peptides\n",
    "iedb_pair_list_pos = [[x, y] for x, y in iedb_pair_list if y == 1]\n",
    "print(\"len(iedb_pair_list_pos) \", len(iedb_pair_list_pos))\n",
    "iedb_pair_list_neg = [[x, y] for x, y in iedb_pair_list if y == 0]\n",
    "print(\"len(iedb_pair_list_neg) \", len(iedb_pair_list_neg))\n",
    "print()\n",
    "\n",
    "if mode == 'evaluation':\n",
    "    normal_hla_file = 'self peptides/' + patient + \"_normal_hla.txt\" # \"mel15_normal_hla.txt\"\n",
    "print(\"normal_hla_file =\", normal_hla_file)\n",
    "if os.path.isfile(normal_hla_file):\n",
    "    with open(normal_hla_file, 'r') as input_handle:\n",
    "        normal_hla = input_handle.readlines()\n",
    "        normal_hla = [x.strip() for x in normal_hla]\n",
    "    normal_hla_neg = [[x, 0] for x in normal_hla]\n",
    "else:\n",
    "    normal_hla_neg = []\n",
    "print(\"len(normal_hla_neg) =\", len(normal_hla_neg))\n",
    "print()\n",
    "\n",
    "print(\"Read IEDB HLA assay table\")\n",
    "print(\"hla_table_file =\", hla_table_file)\n",
    "allele_peptides = {}\n",
    "with open(hla_table_file) as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for row in csv_reader:\n",
    "        peptide = row['Epitope:Description']\n",
    "        allele = row['MHC:Allele Name']\n",
    "        if not (allele in hla_alleles and all([aa in aa_list for aa in peptide])):\n",
    "            continue\n",
    "        if allele in allele_peptides:\n",
    "            allele_peptides[allele].add(peptide)\n",
    "        else:\n",
    "            allele_peptides[allele] = set(peptide)\n",
    "for allele in allele_peptides:\n",
    "    print(allele, len(allele_peptides[allele]))\n",
    "allele_peptides = [x for l in allele_peptides.values() for x in l]\n",
    "print(\"len(allele_peptides) =\", len(allele_peptides))\n",
    "allele_peptides_unique = sorted(list(set(allele_peptides)))\n",
    "print(\"len(allele_peptides_unique) =\", len(allele_peptides_unique))\n",
    "allele_peptides_neg= [[x, 0] for x in allele_peptides_unique]\n",
    "print(\"len(allele_peptides_neg) =\", len(allele_peptides_neg))\n",
    "print()\n",
    "\n",
    "# use self peptides as negative, if they are available\n",
    "if normal_hla_neg:\n",
    "    training_pair_list = iedb_pair_list_pos + normal_hla_neg\n",
    "    print(\"training_pair_list = iedb_pair_list_pos + normal_hla_neg\")\n",
    "else: # use allele-matched hla peptides from IEDB as negative\n",
    "    training_pair_list = iedb_pair_list_pos + allele_peptides_neg\n",
    "    print(\"training_pair_list = iedb_pair_list_pos + allele_peptides_neg\")\n",
    "# combine self and allele peptides as negative\n",
    "# training_pair_list = iedb_pair_list_pos + normal_hla_neg + allele_peptides_neg\n",
    "# print(\"training_pair_list = iedb_pair_list_pos + normal_hla_neg + allele_peptides_neg\")\n",
    "print(\"len(training_pair_list) \", len(training_pair_list))\n",
    "print()\n",
    "\n",
    "# reduce training data to peptides rather than assays \n",
    "print(\"Reduce training_pair_list to unique peptides\")\n",
    "peptide_set = set([x for x, y in training_pair_list])\n",
    "peptide_set_pos = set([x for x, y in training_pair_list if y == 1])\n",
    "peptide_set_neg = set([x for x, y in training_pair_list if y == 0])\n",
    "peptide_overlap = peptide_set_pos.intersection(peptide_set_neg)\n",
    "print(\"len(peptide_set) = \", len(peptide_set))\n",
    "print(\"  len(peptide_set_pos) = \", len(peptide_set_pos))\n",
    "print(\"  len(peptide_set_neg) = \", len(peptide_set_neg))\n",
    "print(\"  len(peptide_overlap) = \", len(peptide_overlap))\n",
    "# convert set to sorted list to maintain the abc order to remove the randomness of the set data type\n",
    "peptide_set_pos = sorted(list(peptide_set_pos))\n",
    "peptide_set_neg = sorted(list(peptide_set_neg))\n",
    "# remove overlap peptides from the negative set\n",
    "training_peptides = [[x, 1] for x in peptide_set_pos] + [[x, 0] for x in peptide_set_neg if x not in peptide_overlap]\n",
    "print(\"Remove overlap peptides from the negative set\")\n",
    "print(\"len(training_peptides) = \", len(training_peptides))\n",
    "print(\"  positive = \", len([y for x, y in training_peptides if y == 1]))\n",
    "print(\"  negative = \", len([y for x, y in training_peptides if y == 0]))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# exclude the evaluation data from the training data\n",
    "print(\"mode =\", mode)\n",
    "if mode == 'evaluation':\n",
    "    print(\"len(training_peptides) =\", len(training_peptides))\n",
    "    mutated_test_file = \"test_csv/test.\" + patient + \".csv\" # \"test.mel15.csv\"\n",
    "    print(\"mutated_test_file =\", mutated_test_file)\n",
    "    mutated_test_list = set()\n",
    "    if mutated_test_file[-3:] == 'csv':\n",
    "        with open(mutated_test_file, 'r') as csv_handle:\n",
    "            csv_reader = csv.DictReader(csv_handle)\n",
    "            mutated_test_list = [row['peptide'] for row in csv_reader]\n",
    "    elif mutated_test_file[-3:] == 'txt':\n",
    "        with open(mutated_test_file, 'r') as file:\n",
    "            mutated_test_list= [x.strip() for x in file.readlines()]\n",
    "    print(\"len(mutated_test_list) =\", len(mutated_test_list))\n",
    "    training_overlap_mutated_test = [x for x, y in training_peptides if x in mutated_test_list]\n",
    "    print(\"len(training_overlap_mutated_test) =\", len(training_overlap_mutated_test))\n",
    "    print(\"training_overlap_mutated_test =\", training_overlap_mutated_test)\n",
    "    print(\"Exclude training_overlap_mutated_test\")\n",
    "    training_peptides = [[x, y] for x, y in training_peptides if x not in training_overlap_mutated_test]\n",
    "    print(\"len(training_peptides) =\", len(training_peptides))\n",
    "    print(\"  positive = \", len([y for x, y in training_peptides if y == 1]))\n",
    "    print(\"  negative = \", len([y for x, y in training_peptides if y == 0]))\n",
    "    print(\"training_peptides[0] = \", training_peptides[0])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# filter length_8_14\n",
    "\n",
    "print(\"len(training_peptides) = \", len(training_peptides))\n",
    "print()\n",
    "\n",
    "print(\"Filter length_8_14\")\n",
    "training_peptides = [[x, y] for x, y in training_peptides if len(x) >= 8 and len(x) <= 14]\n",
    "print(\"len(training_peptides) = \", len(training_peptides))\n",
    "print(\"  positive = \", len([y for x, y in training_peptides if y == 1]))\n",
    "print(\"  negative = \", len([y for x, y in training_peptides if y == 0]))\n",
    "print(\"training_peptides[0] = \", training_peptides[0])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "# split train/valid/test and prepare tensors\n",
    "print(\"len(training_peptides) = \", len(training_peptides))\n",
    "train_valid_set, test_set = train_test_split(training_peptides, test_size=0.1, random_state=99)\n",
    "train_set, valid_set = train_test_split(train_valid_set, test_size=0.1, random_state=99)\n",
    "train_set_neg = [[x, y] for x, y in train_set if y == 0]\n",
    "train_set_pos = [[x, y] for x, y in train_set if y == 1]\n",
    "print(\"len(train_set) = \", len(train_set))\n",
    "print(\"  positive = \", len(train_set_pos))\n",
    "print(\"  negative = \", len(train_set_neg))\n",
    "print(\"train_set[0] = \", train_set[0])\n",
    "print(\"train_set[-1] = \", train_set[-1])\n",
    "print(\"len(valid_set) = \", len(valid_set))\n",
    "print(\"len(test_set) = \", len(test_set))\n",
    "print()\n",
    "\n",
    "def prepare_tensor(training_set):\n",
    "    x_peptide = [x for x, y in training_set]\n",
    "    x_tensor = [[aa2index[aa] for aa in peptide] for peptide in x_peptide]\n",
    "    x_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      x_tensor, \n",
    "      maxlen=MAX_LEN,\n",
    "      dtype='int32',\n",
    "      padding='post',\n",
    "      value=0)\n",
    "    y_tensor = np.array([y for x, y in training_set])\n",
    "    return x_tensor, y_tensor\n",
    "\n",
    "x_valid, y_valid = prepare_tensor(valid_set)\n",
    "x_test, y_test = prepare_tensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4,
     53
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model training \n",
    "# This may take long time so it's better to start with 10 models instead of 100 as in the manuscript.\n",
    "# Each model takes about 1-3 minutes to train, depending on the size of the training data of a patient.\n",
    "\n",
    "def train_model(x_train, y_train, x_valid, y_valid, model_path, num_epochs):\n",
    "#     print(\"\".join([\"=\"] * 80)) # section-separating line\n",
    "#     print(\"train_model()\")\n",
    "\n",
    "    # Model Training\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=8, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(8, recurrent_initializer='glorot_uniform')))\n",
    "    model.add(Dense(1, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    # dropout causes fluctuations ??\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    #print(model.summary())\n",
    "    #model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "    model_checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        verbose=0,\n",
    "                        callbacks=[model_checkpoint])\n",
    "    \n",
    "#     fig, ax = pyplot.subplots(1, 2)\n",
    "#     ax[0].plot(history.history['loss'])\n",
    "#     ax[0].plot(history.history['val_loss'])\n",
    "#     ax[0].set_ylabel('loss')\n",
    "#     ax[0].set_xlabel('epoch')\n",
    "#     ax[0].legend(['loss', 'val_loss'], loc='upper left')\n",
    "#     ax[1].plot(history.history['auc'])\n",
    "#     ax[1].plot(history.history['val_auc'])\n",
    "#     ax[1].set_ylabel('auc')\n",
    "#     ax[1].set_xlabel('epoch')\n",
    "#     ax[1].legend(['auc', 'val_auc'], loc='upper left')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model training\n",
    "print(\"model training\")\n",
    "model_name = \"models/\" + patient + \"_copy\"\n",
    "model_number = 10\n",
    "model_paths = [model_name + \"/\" + \"model\" + \"_\" + patient + \"_copy\" + \"_\" + str(m) + \".h5\" for m in range(model_number)]\n",
    "model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "print(\"len(model_paths) =\", len(model_paths))\n",
    "print(\"model_paths[0] =\", model_paths[0])\n",
    "print(\"model_score_path =\", model_score_path)\n",
    "print()\n",
    "num_epochs = 100\n",
    "for i, path in enumerate(model_paths):\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        continue\n",
    "    \n",
    "    print(\"path =\", path)\n",
    "    \n",
    "    random.seed(99 + i)\n",
    "    \n",
    "#     # no sampling\n",
    "#     train_set = train_set_neg + train_set_pos\n",
    "\n",
    "    # downsampling negative samples\n",
    "    train_set_neg_down = random.sample(train_set_neg, k=min(len(train_set_pos), len(train_set_neg)))\n",
    "    train_set = train_set_neg_down + train_set_pos\n",
    "\n",
    "#     # downsampling positive samples\n",
    "#     train_set_pos_down = random.sample(train_set_pos, k=len(train_set_neg))\n",
    "#     train_set = train_set_pos_down + train_set_neg\n",
    "    \n",
    "    random.shuffle(train_set)\n",
    "    x_train, y_train = prepare_tensor(train_set)\n",
    "    \n",
    "    # model training\n",
    "    model = train_model(x_train, y_train, x_valid, y_valid, path, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# make predictions on valid set and save the results for model selection\n",
    "if not os.path.isfile(model_score_path):\n",
    "    print(\"make predictions on valid set and save the results for model selection\")\n",
    "    x_testing, y_testing = prepare_tensor(valid_set)\n",
    "#     print(\"combine valid + test for more accurate model selection\")\n",
    "#     x_testing, y_testing = prepare_tensor(valid_set + test_set)\n",
    "    print(\"len(y_testing) =\", len(y_testing))\n",
    "    print()\n",
    "    y_pred_list = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "        model = load_model(path)\n",
    "        y_pred = model.predict(x_testing).flatten()\n",
    "        y_pred_list.append(y_pred)\n",
    "    model_score = [y_testing, y_pred_list]\n",
    "    with open(model_score_path, 'wb') as file:\n",
    "        pickle.dump(model_score, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# PREDICTION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     47,
     52,
     57,
     66,
     73,
     94
    ]
   },
   "outputs": [],
   "source": [
    "# prediction functions\n",
    "\n",
    "def model_selection(model_name):\n",
    "\n",
    "    print(\"model selection\")\n",
    "    model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "    print(\"model_score_path =\", model_score_path)\n",
    "    with open(model_score_path, 'rb') as file:\n",
    "        model_score = pickle.load(file) # y_testing, y_pred_list\n",
    "    y_testing, y_pred_list = model_score\n",
    "    print(\"len(y_pred_list) =\", len(y_pred_list))\n",
    "    print()\n",
    "\n",
    "    print(\"AUC of the average of the best models\")\n",
    "    testing_auc_list = [roc_auc_score(y_testing, y_pred) for y_pred in y_pred_list]\n",
    "#     pyplot.boxplot(testing_auc_list)\n",
    "    sorted_auc_indices = sorted(range(len(testing_auc_list)), key=lambda k: -testing_auc_list[k])\n",
    "    for best in [1, 10, 20, 40, 60, 80, len(testing_auc_list)]:\n",
    "        y_pred_avg = np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "        y_pred_avg_auc = roc_auc_score(y_testing, y_pred_avg)\n",
    "        print(best, \"best models\", y_pred_avg_auc)\n",
    "    print()\n",
    "    \n",
    "#     # plot the score distribution of the average of the best models\n",
    "#     print(\"plot the score distribution of the average of the best models\")\n",
    "#     best = 10\n",
    "#     print(best, \"best models\")\n",
    "#     y_score =  np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "#     fig, ax = pyplot.subplots(1, 2)\n",
    "#     fpr, tpr, _ = roc_curve(y_testing, y_score)\n",
    "#     auc = roc_auc_score(y_testing, y_score)\n",
    "#     ax[0].plot(fpr,tpr,label=\"data 1, auc={:.2f}\".format(auc))\n",
    "#     ax[0].set_ylabel('True Positive Rate')\n",
    "#     ax[0].set_xlabel('False Positive Rate')\n",
    "#     ax[0].legend(loc=4)\n",
    "#     y_score_0 = [b for a, b in zip(y_testing, y_score) if a == 0]\n",
    "#     y_score_1 = [b for a, b in zip(y_testing, y_score) if a == 1]\n",
    "#     my_dict = {'neg': y_score_0, 'pos': y_score_1}\n",
    "#     ax[1].boxplot(my_dict.values())\n",
    "#     ax[1].set_xticklabels(my_dict.keys())\n",
    "#     pd_0 = pd.DataFrame({'neg': y_score_0})\n",
    "#     pd_1 = pd.DataFrame({'pos': y_score_1})\n",
    "#     pd.concat([pd_0, pd_1], ignore_index=True, axis=1).describe()\n",
    "\n",
    "    return sorted_auc_indices\n",
    "\n",
    "\n",
    "def predict(model_list, model_score, input_file, output_file):\n",
    "#     print(\"predict()\")\n",
    "#     print(\"input_file = \", input_file)\n",
    "#     print(\"output_file = \", output_file)\n",
    "\n",
    "    if input_file[-3:] == 'csv':\n",
    "        with open(input_file, 'r') as input_handle:\n",
    "            csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "            csv_fieldnames = csv_reader.fieldnames\n",
    "            csv_records = list(csv_reader)\n",
    "    elif input_file[-3:] == 'txt':\n",
    "        with open(input_file, 'r') as file:\n",
    "            csv_fieldnames = ['peptide']\n",
    "            csv_records = [{'peptide':x.strip()} for x in file.readlines()]\n",
    "    print(\"number of input peptides =\", len(csv_records))\n",
    "    print()\n",
    "\n",
    "    x_peptide = [record['peptide'] for record in csv_records]\n",
    "    x_tensor = [[aa2index[aa] for aa in peptide] for peptide in x_peptide]\n",
    "    x_tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      x_tensor, \n",
    "      maxlen=MAX_LEN,\n",
    "      dtype='int32',\n",
    "      padding='post',\n",
    "      value=0)\n",
    "    y_pred_list = []\n",
    "    for model in model_list:\n",
    "        y_pred = model.predict(x_tensor).flatten()\n",
    "        y_pred_list.append(y_pred)\n",
    "    y_pred = np.mean(y_pred_list, axis=0)\n",
    "\n",
    "    model_y_test, model_y_pred = model_score\n",
    "    model_y_pred_0 = [b for (a, b) in zip(model_y_test, model_y_pred) if a == 0]\n",
    "    model_y_pred_1 = [b for (a, b) in zip(model_y_test, model_y_pred) if a == 1]\n",
    "    with open(output_file, 'w') as output_handle:\n",
    "        csv_fieldnames += ['dpImmun', 'dpImmun_neg_pct', 'dpImmun_pos_pct', 'dpImmun rank']\n",
    "        csv_writer = csv.DictWriter(output_handle, csv_fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for record, pred in zip(csv_records, list(y_pred)):\n",
    "            record.update({'dpImmun': pred,\n",
    "                           'dpImmun_neg_pct': np.sum(pred >= model_y_pred_0) / len(model_y_pred_0),\n",
    "                           'dpImmun_pos_pct': np.sum(pred >= model_y_pred_1) / len(model_y_pred_1),\n",
    "                           'dpImmun rank': 1 - np.sum(pred >= model_y_pred_0) / len(model_y_pred_0),\n",
    "                          })\n",
    "            csv_writer.writerow(record)\n",
    "\n",
    "            \n",
    "def patient_prediction(input_file, output_file, model_name):\n",
    "    \n",
    "    print(\"patient prediction\")\n",
    "    print(\"input_file = \", input_file)\n",
    "    print(\"output_file = \", output_file)\n",
    "    print()\n",
    "\n",
    "    sorted_auc_indices = model_selection(model_name)\n",
    "    model_number = len(sorted_auc_indices)\n",
    "    model_paths = [model_name + \"/\" + \"model\" + \"_\" + patient + \"_copy\" + \"_\" + str(m) + \".h5\" for m in range(model_number)]\n",
    "    model_score_path = model_name + \"/\" + \"model_score\" + \".pkl\"\n",
    "    print(\"len(model_paths) =\", len(model_paths))\n",
    "    print(\"model_paths[0] =\", model_paths[0])\n",
    "    print(\"model_score_path =\", model_score_path)\n",
    "    print()\n",
    "\n",
    "    # use average of the best models for predictions\n",
    "    best = 10\n",
    "    print(best, \"best models\")\n",
    "    print()\n",
    "    model_list = [load_model(model_paths[i]) for i in sorted_auc_indices[:best]]\n",
    "    with open(model_score_path, 'rb') as file:\n",
    "        model_score = pickle.load(file) # y_testing, y_pred_list\n",
    "    y_testing, y_pred_list = model_score\n",
    "    y_pred_avg = np.mean([y_pred_list[i] for i in sorted_auc_indices[:best]], axis=0)\n",
    "    predict(model_list, [y_testing, y_pred_avg], input_file, output_file)\n",
    "\n",
    "\n",
    "input_file = \"test_csv/test100.\" + patient + \".csv\"\n",
    "output_file = input_file + \".dpimmun.csv\"\n",
    "model_name = \"models/\" + patient + \"_copy\"\n",
    "patient_prediction(input_file, output_file, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "# EVALUATION\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     7,
     27
    ]
   },
   "outputs": [],
   "source": [
    "# evaluation functions\n",
    "\n",
    "def evaluate_sub(y_test, y_score):\n",
    "    auc  = roc_auc_score(y_test, y_score)\n",
    "    return auc\n",
    "\n",
    "\n",
    "def evaluate(input_file, tool_name):\n",
    "    y_test = []\n",
    "    y_score = []\n",
    "    with open(input_file, 'r') as input_handle:\n",
    "        csv_reader = csv.DictReader(input_handle, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            peptide = row['peptide']\n",
    "            response = row['response']\n",
    "            assert response == \"positive\" or response == \"negative\"\n",
    "            response = 1 if response == \"positive\" else 0\n",
    "            y_test.append(response)\n",
    "            score = float(row[tool_name])\n",
    "            if \"rank\" in tool_name:\n",
    "                score = 100 - score\n",
    "            y_score.append(score)\n",
    "    y_test = np.array(y_test)\n",
    "    y_score = np.array(y_score)\n",
    "    return y_test, y_score, evaluate_sub(y_test, y_score)\n",
    "\n",
    "\n",
    "def patient_evaluation(eval_file):\n",
    "    \n",
    "    print(\"auc evaluation\")\n",
    "    print(\"eval_file =\", eval_file)\n",
    "    print()\n",
    "    tools = ['dpImmun', 'PRIME2 %rank', 'NetMHCpan %rank', 'IEDB']\n",
    "    tools_auc = [evaluate(eval_file, tool) for tool in tools]\n",
    "    names = ['DeepImmun', 'PRIME', 'NetMHCpan', 'IEDB']\n",
    "    colors = ['red', 'orange', 'green', 'blue']\n",
    "\n",
    "    print(\"pos_ranks\")\n",
    "    pyplot.title('Receiver Operating Characteristic Curves')\n",
    "    for y, n, c in zip(tools_auc, names, colors):\n",
    "        fpr, tpr, threshold = roc_curve(y[0], y[1])\n",
    "        pyplot.plot(fpr, tpr, color=c, label=\"{0:s}, AUC={1:0.2f}\".format(n, y[2]))\n",
    "        sorted_indices = np.argsort(-y[1])\n",
    "        pos_ranks = [100*(rank+1)/len(y[0]) for rank, index in enumerate(sorted_indices) if y[0][index] == 1]\n",
    "        pos_ranks = ','.join(['{0:.1f}'.format(x) for x in pos_ranks])\n",
    "        print(n, '{0:.2f}'.format(y[2]), pos_ranks, sep=';')\n",
    "    pyplot.legend(loc = 'lower right')\n",
    "    pyplot.xlim([0, 1])\n",
    "    pyplot.ylim([0, 1.05])\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "#     pyplot.savefig('test100.18patients.csv.dpimmun_copy.csv.png', dpi=600)\n",
    "    print()\n",
    "   \n",
    "\n",
    "eval_file = \"test_csv/test100.\" + patient + \".csv.dpimmun_copy.csv\"\n",
    "patient_evaluation(eval_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_tf2",
   "language": "python",
   "name": "python3_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
